name: Colab GPU Benchmark

on:
  workflow_dispatch:
    inputs:
      model:
        description: 'Model to benchmark'
        required: true
        default: 'facebook/opt-6.7b'
      backend:
        description: 'Backend to use'
        required: true
        default: 'pytorch'
        type: choice
        options:
          - pytorch
          - tensorrt
          - both
      batch_sizes:
        description: 'Batch sizes to test (space-separated)'
        required: false
        default: '1 2 4'
      precisions:
        description: 'Precisions to test (space-separated)'
        required: false
        default: 'fp16'
        type: choice
        options:
          - fp16
          - int8
          - fp16 int8

jobs:
  setup-colab:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v3
    
    - name: Create Colab Notebook
      run: |
        mkdir -p notebooks
        cat > notebooks/benchmark.ipynb << 'EOL'
        {
         "cells": [
          {
           "cell_type": "markdown",
           "metadata": {
            "id": "instructions"
           },
           "source": [
            "# LLM Turbo Benchmark\n",
            "\n",
            "This notebook will run the benchmark with the following configuration:\n",
            "- Model: ${{ github.event.inputs.model || 'facebook/opt-6.7b' }}\n",
            "- Backend: ${{ github.event.inputs.backend || 'pytorch' }}\n",
            "- Batch Sizes: ${{ github.event.inputs.batch_sizes || '1 2 4' }}\n",
            "- Precisions: ${{ github.event.inputs.precisions || 'fp16' }}\n",
            "\n",
            "## Instructions\n",
            "1. Run each cell in sequence\n",
            "2. Wait for each cell to complete before running the next\n",
            "3. Download results when complete"
           ]
          },
          {
           "cell_type": "code",
           "execution_count": null,
           "metadata": {
            "colab": {
             "base_uri": "https://localhost:8080/"
            },
            "id": "setup"
           },
           "outputs": [],
           "source": [
            "# Install system dependencies\n",
            "!apt-get update\n",
            "!apt-get install -y python3-pip python3-dev\n",
            "\n",
            "# Clone repository\n",
            "!git clone https://github.com/${{ github.repository }}.git\n",
            "\n",
            "# Install Python dependencies\n",
            "!cd llm-turbo-bench && pip install -r requirements.txt\n",
            "\n",
            "# Check GPU availability\n",
            "import torch\n",
            "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
            "if torch.cuda.is_available():\n",
            "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
            "    print(f\"CUDA version: {torch.version.cuda}\")"
           ]
          },
          {
           "cell_type": "code",
           "execution_count": null,
           "metadata": {
            "id": "benchmark"
           },
           "outputs": [],
           "source": [
            "import os\n",
            "import sys\n",
            "from pathlib import Path\n",
            "\n",
            "# Change to project directory\n",
            "os.chdir('llm-turbo-bench')\n",
            "\n",
            "# Check if TensorRT is available\n",
            "try:\n",
            "    import tensorrt\n",
            "    tensorrt_available = True\n",
            "except ImportError:\n",
            "    tensorrt_available = False\n",
            "    print(\"TensorRT not available, will use PyTorch backend only\")\n",
            "\n",
            "# Determine backend to use\n",
            "backend = \"${{ github.event.inputs.backend || 'pytorch' }}\"\n",
            "if backend == \"tensorrt\" and not tensorrt_available:\n",
            "    print(\"TensorRT backend requested but not available. Falling back to PyTorch.\")\n",
            "    backend = \"pytorch\"\n",
            "elif backend == \"both\" and not tensorrt_available:\n",
            "    print(\"TensorRT backend requested but not available. Using PyTorch only.\")\n",
            "    backend = \"pytorch\"\n",
            "\n",
            "# Run benchmark\n",
            "!python src/main.py \\\n",
            "  --model ${{ github.event.inputs.model || 'facebook/opt-6.7b' }} \\\n",
            "  --backend {backend} \\\n",
            "  --batch-sizes ${{ github.event.inputs.batch_sizes || '1 2 4' }} \\\n",
            "  --precisions ${{ github.event.inputs.precisions || 'fp16' }} \\\n",
            "  --output-dir results"
           ]
          },
          {
           "cell_type": "code",
           "execution_count": null,
           "metadata": {
            "id": "upload"
           },
           "outputs": [],
           "source": [
            "from google.colab import files\n",
            "import shutil\n",
            "import os\n",
            "\n",
            "# Check if results directory exists\n",
            "if os.path.exists('results'):\n",
            "    shutil.make_archive('results', 'zip', 'results')\n",
            "    files.download('results.zip')\n",
            "else:\n",
            "    print(\"No results directory found. Benchmark may have failed.\")"
           ]
          }
         ],
         "metadata": {
          "colab": {
           "provenance": []
          },
          "kernelspec": {
           "display_name": "Python 3",
           "name": "python3"
          }
         },
         "nbformat": 4,
         "nbformat_minor": 0
        }
        EOL

    - name: Upload Notebook
      uses: actions/upload-artifact@v4
      with:
        name: colab-notebook
        path: notebooks/benchmark.ipynb
        retention-days: 1

  notify:
    needs: setup-colab
    runs-on: ubuntu-latest
    steps:
    - name: Notify User
      run: |
        echo "Benchmark notebook has been generated. Please:"
        echo "1. Download the notebook from the artifacts"
        echo "2. Upload it to Google Colab (https://colab.research.google.com)"
        echo "3. Run the cells in sequence"
        echo "4. Download the results when complete"
        echo ""
        echo "Note: TensorRT may not be available in Colab. The notebook will automatically"
        echo "fall back to PyTorch if TensorRT is not available." 