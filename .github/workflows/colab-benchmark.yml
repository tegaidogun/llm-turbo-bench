name: Colab GPU Benchmark

on:
  workflow_dispatch:
    inputs:
      model:
        description: 'Model to benchmark'
        required: true
        default: 'facebook/opt-6.7b'
      backend:
        description: 'Backend to use'
        required: true
        default: 'pytorch'
        type: choice
        options:
          - pytorch
          - tensorrt
          - both
      batch_sizes:
        description: 'Batch sizes to test (space-separated)'
        required: false
        default: '1 2 4'
      precisions:
        description: 'Precisions to test (space-separated)'
        required: false
        default: 'fp16'
        type: choice
        options:
          - fp16
          - int8
          - fp16 int8

jobs:
  setup-colab:
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v3
    
    - name: Create Colab Notebook
      run: |
        mkdir -p notebooks
        cat > notebooks/benchmark.ipynb << 'EOL'
        {
         "cells": [
          {
           "cell_type": "markdown",
           "metadata": {
            "id": "instructions"
           },
           "source": [
            "# LLM Turbo Benchmark\n",
            "\n",
            "This notebook will run the benchmark with the following configuration:\n",
            "- Model: ${{ github.event.inputs.model || 'facebook/opt-6.7b' }}\n",
            "- Backend: ${{ github.event.inputs.backend || 'pytorch' }}\n",
            "- Batch Sizes: ${{ github.event.inputs.batch_sizes || '1 2 4' }}\n",
            "- Precisions: ${{ github.event.inputs.precisions || 'fp16' }}\n",
            "\n",
            "## Instructions\n",
            "1. Run each cell in sequence\n",
            "2. Wait for each cell to complete before running the next\n",
            "3. Download results when complete"
           ]
          },
          {
           "cell_type": "code",
           "execution_count": null,
           "metadata": {
            "colab": {
             "base_uri": "https://localhost:8080/"
            },
            "id": "setup"
           },
           "outputs": [],
           "source": [
            "import os\n",
            "import sys\n",
            "import subprocess\n",
            "\n",
            "def run_command(command):\n",
            "    try:\n",
            "        result = subprocess.run(command, shell=True, check=True, text=True, capture_output=True)\n",
            "        print(result.stdout)\n",
            "        return True\n",
            "    except subprocess.CalledProcessError as e:\n",
            "        print(f\"Error: {e.stderr}\", file=sys.stderr)\n",
            "        return False\n",
            "\n",
            "# First, download the repository as a ZIP file\n",
            "repo_url = \"https://github.com/${{ github.repository }}/archive/refs/heads/main.zip\"\n",
            "if not run_command(f\"wget {repo_url} -O repo.zip\"):\n",
            "    raise Exception(\"Failed to download repository\")\n",
            "\n",
            "# Extract the ZIP file\n",
            "if not run_command(\"unzip repo.zip\"):\n",
            "    raise Exception(\"Failed to extract repository\")\n",
            "\n",
            "# Move into the repository directory\n",
            "repo_dir = \"${{ github.repository.split('/')[1] }}-main\"\n",
            "os.chdir(repo_dir)\n",
            "\n",
            "# Install dependencies\n",
            "if not run_command(\"pip install -r requirements.txt\"):\n",
            "    raise Exception(\"Failed to install dependencies\")"
           ]
          },
          {
           "cell_type": "code",
           "execution_count": null,
           "metadata": {
            "id": "benchmark"
           },
           "outputs": [],
           "source": [
            "import os\n",
            "import subprocess\n",
            "import sys\n",
            "\n",
            "def run_command(command):\n",
            "    try:\n",
            "        result = subprocess.run(command, shell=True, check=True, text=True, capture_output=True)\n",
            "        print(result.stdout)\n",
            "        return True\n",
            "    except subprocess.CalledProcessError as e:\n",
            "        print(f\"Error: {e.stderr}\", file=sys.stderr)\n",
            "        return False\n",
            "\n",
            "benchmark_command = f\"\"\"python src/main.py \\\n",
            "  --model ${{ github.event.inputs.model || 'facebook/opt-6.7b' }} \\\n",
            "  --backend ${{ github.event.inputs.backend || 'pytorch' }} \\\n",
            "  --batch-sizes ${{ github.event.inputs.batch_sizes || '1 2 4' }} \\\n",
            "  --precisions ${{ github.event.inputs.precisions || 'fp16' }} \\\n",
            "  --output-dir results\"\"\"\n",
            "\n",
            "if not run_command(benchmark_command):\n",
            "    raise Exception(\"Benchmark failed\")"
           ]
          },
          {
           "cell_type": "code",
           "execution_count": null,
           "metadata": {
            "id": "upload"
           },
           "outputs": [],
           "source": [
            "from google.colab import files\n",
            "import shutil\n",
            "import os\n",
            "\n",
            "try:\n",
            "    # Create results directory if it doesn't exist\n",
            "    os.makedirs('results', exist_ok=True)\n",
            "    \n",
            "    # Create ZIP archive\n",
            "    shutil.make_archive('results', 'zip', 'results')\n",
            "    \n",
            "    # Download the results\n",
            "    files.download('results.zip')\n",
            "    print(\"Results downloaded successfully\")\n",
            "except Exception as e:\n",
            "    print(f\"Error downloading results: {e}\")"
           ]
          }
         ],
         "metadata": {
          "colab": {
           "provenance": []
          },
          "kernelspec": {
           "display_name": "Python 3",
           "name": "python3"
          }
         },
         "nbformat": 4,
         "nbformat_minor": 0
        }
        EOL

    - name: Upload Notebook
      uses: actions/upload-artifact@v4
      with:
        name: colab-notebook
        path: notebooks/benchmark.ipynb
        retention-days: 1

  notify:
    needs: setup-colab
    runs-on: ubuntu-latest
    steps:
    - name: Notify User
      run: |
        echo "Benchmark notebook has been generated. Please:"
        echo "1. Download the notebook from the artifacts"
        echo "2. Upload it to Google Colab (https://colab.research.google.com)"
        echo "3. Run the cells in sequence"
        echo "4. Download the results when complete" 